## Contents
### Introduction
### Statistical Learning
#### What is Statistical Learning
#### Assessing Model Accuracy
#### Lab: Introduction to Python
#### Exercises
### Linear Regression
#### Simple Linear Regression
#### Multiple Linear Regression
#### Other Considerations in the Regression Model
#### The Marketing Plan
#### Comparison of Linear Regression with K-Nearest Neighbors
#### Lab: Linear Regression
#### Exercises
### Classification
#### An Overview of Classification
#### Why Not Linear Regression
#### Logistic Regression
#### Generative Models of Classification
#### A Comparison of Classification Models
#### Generalized Linear Models
#### Lab: Logistic Regression, LDA, QDA, KNN
#### Exercises
### Resampling Methods
#### Cross-Validation
#### The Bootstrap
#### Lab: Cross-Validation and the Bootstrap
#### Exercises
### Linear Model Selection and Regularization
#### Subset Selection
#### Shrinkage Methods
#### Dimension Reduction Methods
#### Considerations in Higher Dimensions
#### Lab: Linear Models and Regularization Methods
#### Exercises
### Moving Beyond Linearity
#### Polynomial Regression
#### Step Functions
#### Basis Functions
#### Regression Splines
#### Smoothing Splines
#### Local Regression
#### Local Regression
#### Generalized Additive Models
#### Lab: Non-Linear Modeling
#### Exercises
### Tree-Based Methods
#### The Basics of Decision Trees
#### Bagging, Random Forests, Boosting, and Baynesian Additive Regression Trees
#### Lab: Tree-Based Methods
#### Exercises
### Support Vector Machines
#### Maximal Margin Classifier
#### Support Vector Classifiers
#### Support Vector Machines
#### SVMs with More than Two Classes
#### Relationship to Logistic Regression
#### Lab: Support Vector Machines
#### Exercises
### Deep Learning
#### Single Later Neural Networks
#### Multilater Neural Networks
#### Convolutional Neural Networks
#### Document Classification
#### Recurrent Neural Networks
#### When to Use Deep Learning
#### Fitting a Neural Network
#### Interpolation and Double Descent
#### Lab: Deep Learning
#### Exercises
### Survival Analysis and Censored Data
#### Survival and Censoring Times
#### A Closer Look at Censoring
#### The Kaplan-Meier Survival Curve
#### The Log-Rank Test
#### Regression Models with a Survival Response
#### Shrinkage for the Cox Model
#### Additional Topics
#### Lab: Survival Analysis
#### Exercises
### Unsupervised Learning
#### The Challenge of Unsupervised Learning
#### Principal Components Analysis
#### Missing Values and Matrix Completion
#### Clustering Methods
#### Labs: Unsupervised Learning
#### Exercises
### Multiple testing
#### A Quick Review of Hypothesis Testing
#### The Challenge of Multiple Testing
#### The Family-Wise Error Rate
#### The False Discovery Rate
#### A Re-Sampling Approach to p-Values and False Discovery Rates
#### Lab: Multiple Testing
#### Exercises
### Index
## Outline
### Preface
In addition to a review of linear regression, ISLR covers many of todayâ€™s most important statistical and machine learning approaches, including resampling, sparse methods for classifcation and regression, generalized additive models, tree-based methods, support vector machines, deep learning, survival analysis, clustering, and multiple testing.
### Introduction
