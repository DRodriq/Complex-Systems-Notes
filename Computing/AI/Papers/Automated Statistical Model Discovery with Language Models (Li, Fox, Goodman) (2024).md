[Article](https://openreview.net/pdf?id=B5906M4Wnd)
**All sections are direct quotes from the corresponding section of the paper**
**Selection of quotes was my own**
## Abstract
Statistical model discovery is a challenging search over a vast space of models subject to domainspecific constraints. Efficiently searching over this space requires expertise in modeling and the problem domain.
We cast our automated procedure within the principled framework of Box’s Loop: the LM iterates between proposing statistical models represented as probabilistic programs, acting as a modeler, and critiquing those models, acting as a domain expert. By leveraging LMs, we do not have to define a domain-specific language of models or design a handcrafted search procedure, which are key restrictions of previous systems. We evaluate our method in three settings in probabilistic modeling: searching within a restricted space of models, searching over an open-ended space, and improving expert models under natural language constraints (e.g., this model should be interpretable to an ecologist).
## Introduction
Modeling, or generating a parsimonious but explanatory representation of a complex system, is at the heart of scientific discovery. Model discovery is challenging because it involves searching over a vast space of candidate models subject to domain-specific constraints (e.g., find the best model that remains interpretable to domain experts). Efficiently searching over the space requires extensive human expertise: modelers need broad knowledge of different modeling approaches and must work closely with domain experts to adapt these approaches to a given problem domain. 

Automated model discovery is not a new ambition. Previous systems have been successfully deployed for discovering physical laws, *reverse-engineering non-linear dynamical systems* ([[Distilling free-form natural laws from experimental data (Schmidt, Lipson) (2019)]]), nonparametric regression and unsupervised learning. However, in these systems, a human
expert had to carefully design a domain specific language (DSL) of models and specify a hand-crafted search procedure for composing models in that DSL.

These systems also compromised flexibility for automation: rather than choosing a model class bestsuited for a problem, experts chose models that compose
conveniently. This breaks the core principle of separation of modeling from inference.

As we saw above, there are two key roles in the model discovery pipeline: the domain expert and the modeler. We hypothesize that LMs can supplement these roles and reduce the human expertise required in model discovery.

## 3.3 Improving classic models under modeling constraints
In the previous experiment, we explored BoxLM’s ability to identify models tabula rasa (e.g., without any initial seed model). However, in many scientific settings, we begin with a well-known model and are tasked with improving it. Here, we explore BoxLM’s ability to improve upon a Lotka-Volterra model of predator-prey dynamics. In addition, a crucial component of model discovery is respecting “soft” modeling constraints that are easy to express in natural language but hard to formalize (e.g., ecologists should think this is a plausible model). We therefore illustrate another advantage of BoxLM: we can express these modeling constraints in natural language and use them to drive LM proposals.

**Dataset:** To create our dataset, we simulate data from the following “perturbed” Lotka-Volterra dynamics
$db/dt = {\alpha}b-{\beta}bc$
$dc/dt=-{\gamma}c+{\delta}bc^{.95}$

**Setup:** BoxLM is tasked with implementing an ODE model in Python using Jax (Bradbury et al., 2018). Estimating the parameters of Lotka-Volterra models via Bayesian inference is challenging. We instead learn the parameters via gradient descent which can be straightforwardly implemented using modern automatic differentiation libraries (Chen et al., 2018; Kidger, 2021); in particular, we use diffrax (Kidger, 2021), a Jax-based ODE library that supports learning ODE parameters via backpropagation. We consider three variations: warm-start with constraints (WS-Constraint), warm-start with no constraints (WS-No Constraint), and no warm-start (No-WS) that differ in their initial seed program and the initial instructions which express modeling constraints. In all variations, we provide the LM with a scatter plot of training datapoints. In the no warm-start variation, we provide the LM with an implementation of standard Lotka-Volterra dynamics using diffrax and the predictions obtained from fitting standard Lotka-Volterra to the training data. In both warm-start variations, we provide the LM with (1) an implementation of a hybrid neural ODE that introduces an additive correction term to the predator dynamics, parameterized by a multilayer perceptron (MLP), and (2) the predictions obtained from fitting this model to the training data. In the constrained warm-start variation, we ask the LM to produce a hybrid neural ODE model that is interpretable to an ecology expert who suggested a Holling’s type II response (Rosenzweig & MacArthur, 1963). In the unconstrained warm-start variation, we provide the same seed program but do not impose this additional interpretability constraint. For models with both neural and physical components, we employ a two-stage learning procedure so that the neural component does not dominate the dynamics; see Appendix C for details.

**Results:** In Figure 4 (left), we plot the predictions obtained from integrating the learned dynamics for an ODE proposed by BoxLM, the training data points generated from the true dynamics, and the predictions from the standard Lotka-Volterra model. We fit free parameters to the training data via gradient descent. The grey region indicates the extrapolation region. BoxLM can significantly improve upon the standard LotkaVolterra model by introducing corrections to the dynamics (Figure 4). The standard Lotka-Volterra model cannot capture the decreasing amplitude in the data; furthermore, there is a slight phase shift relative to the training datapoints. In contrast, BoxLM identifies an ODE that captures these properties and extrapolates accurately. In Figure 4 (right), we compare these programs against a neural ODE base line, and a hybrid neural ODE baseline that incorporates a multiplicative correction (parameterized by an MLP) to the predator-prey interaction term in the predator equation. See Section C of the Appendix for details on these baselines. For the LM variations, we report the average test MAE across three runs. In Figure 4, we see that all BoxLM variations outperform the baselines.
In Figure 5, we present code snippets corresponding to representative programs proposed in the constrained and unconstrained variations. These snippets show how natural language constraints can guide BoxLM towards more flexible models that retain interpretability. For the variation with no natural language constraints (WS-No Constraint), BoxLM takes a purely empirical approach. In particular, BoxLM adjusts the scaling terms on the additive MLP correction term. For the WS-Constraint variation, BoxLM proposes a hybrid approach integrating the neural approach in the prompt with classic models in the literature; importantly, even though BoxLM is asked to balance interpretability and flexibility, BoxLM still identifies programs that outperform the neural ODE and standard Lotka-Volterra baselines. One approach BoxLM proposes is an extension of the Rosenzweig and MacArthur model with a Holling’s type II functional response (Rosenzweig & MacArthur, 1963) to allow a static parameter to depend dynamically on the prey density: BoxLM models the handling time, or the time a predator spends “processing” a prey, as a nonlinear function of the prey density via an MLP. These results show how we can use natural language to drive BoxLM towards models that balance flexibility and interpretability.
## Impact Statement 
This paper presents work whose goal is to partially automate statistical modeling. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here. 
## Notes
Try and recreate these results. 
The model discovery here demonstrates the close link between neural networks and dynamical systems, especially nonlinear systems that are hard to create and understand models for. Neural networks can help us simulate and model complex, nonlinear systems and nonlinear dynamics can in turn help us understand neural networks. I think there is a lot of potential with studying learning and training dynamics by better understanding dynamical systems. 